---
title: "MetalLB"
description: ""
summary: ""
date: "2022-05-30"
menu: "main"
draft: true
tags:
- kubernetes
categories:
- "technology"
---

[官方文档](https://metallb.universe.tf/)

## 为什么使用?

Kubernetes没有提供裸适用于金属集群的网络负载均衡器实现, 也就是LoadBalancer类型的Service. Kubernetes 附带的网络负载均衡器的实现都是调用各种 IaaS 平台（GCP、AWS、Azure ……）的胶水代码。 如果您没有在受支持的 IaaS 平台（GCP、AWS、Azure...）上运行，LoadBalancers 在创建时将一直保持在`pending`状态。

裸金属集群的运维人员只剩下两个较小的工具来将用户流量引入集群内: `NodePort`和`externalIPs`类型Service. 这两种在生产环境使用有很大的缺点, 这让裸金属集群成为Kubernetes生态中的第二类选择, 并不是首选.

MetalLB的目的是实现一个网络负载均衡器来与标准的网络设备集成, 这样外部服务就可以尽可能的正常工作了.

## 要求

MetalLB 要求如下:


- 一个 Kubernetes 集群, Kubernetes 版本 1.13.0+, 没有网络负载均衡器功能.
- 可以与 MetalLB 共存的集群网络配置。
- 一些供 MetalLB 分发的 IPv4 地址。
- 当使用 BGP 操作模式时，您将需要一台或多台能够广播 BGP 的路由器。
- 使用 L2 操作模式时，节点之间必须允许 7946 端口（TCP 和 UDP，可配置其他端口）上的流量，这是 [memberlist](https://github.com/hashicorp/memberlist) 的要求。

## 功能

MetalLB 是作为 Kubernetes 中的一个组件, 提供了一个中网络负载均衡器的实现. 简单来说, 在非公有云环境搭建的集群上, 不能使用公有云的负载均衡器, 它可以让你在集群中创建 LoadBalancer 类型的 Service.

为了提供这样的服务, 它具备两个功能: 地址分配、对外发布

### 地址分配

在公有云的 Kubernetes 集群中, 你申请一个负载均衡器, 云平台会给你分配一个 IP 地址. 在裸金属集群中, MetalLB 来做地址分配.

MetalLB 不能凭空造 IP, 所以你需要提供供它使用的 IP 地址池. 在 Service 的创建和删除过程中, MetalLB 会对 Service 分配和回收 IP, 这些都是你配置的地址池中的 IP.

如何获取 MetalLB 的 IP 地址池取决于您的环境。 如果您在托管设施中运行裸机集群，您的托管服务提供商可能会提供 IP 地址供出租。 在这种情况下，您将租用例如 /26 的 IP 空间（64 个地址），并将该范围提供给 MetalLB 以用于集群服务。

同样, 如果你的集群是纯私有的, 可以提供一个没有暴露到网络中的相邻的 LAN 网段. 这种情况下, 你可以抽取私有地址空间( RFC1918 地址)中的一段 IPs 地址, 分配给 MetalLB. 这种地址是免费的, 只要你只把它提供给当前 LAN 内的集群 Services, 它们就能正常工作.

或者你可以两者都用! MetalLB 可以让你定义多个地址池, 不需要关心这些地址的`类别`.

### 对外发布

当 MetalLB 给 Service 分配一个对外使用的IP之后, 它需要让集群所在的网络知道这个 IP 的存在. MetalLB 使用标准的网络/路由协议来实现, 这要看具体的工作模式: ARP、NDP 或者 BGP.

#### 2层模式 (ARP/NDP)

在2层模式下, 集群中的机器使用标准地址发现协议把这些 IPs 通知本地网络. 从 LAN 的角度看, 这台服务器有多个 IP 地址. 这个模式的详细行为还有局限性下面会介绍.

#### BGP

在 BGP 模式下, 集群中的所有机器与临近的路由器建立 BGP 对等会话, 告诉他们如何路由 Service IPs. 得益于 BGP 的策略机制, 使用 BGP 能实现真正的多节点负载均衡和细粒度的流量控制. 下面会介绍更多操作和局限性方面的细节.

## 工作模式

### 2层模式

在2层工作模式下, 一个节点负责向本地网络发布服务. 从网络的角度看, 更像是这台服务器的网卡有多个 IP 地址. 在底层, MetalLB 会响应适用于 IPv4 的 ARP 请求和适用于 IPv6 的 NDP 请求. 这个工作模式的最大的优势就是适应性强: 它能工作在任何以太网内, 没有特殊的硬件要求, 不需要花哨的路由器.

#### 负载均衡行为

在2层模式下, 一个 Service IP 的流量都会到一个节点上. 在该节点上, `kube-proxy` 将流量分发到服务具体的 pods 上. L2 并没有实现负载均衡. 但是, 它实现了一个错误转移机制, 这样当领袖节点故障之后, 另一个节点就会接管这些 IP 地址. 如果领袖节点因为某些原因故障了, 故障转移是自动的: 使用 [memberlist](https://github.com/hashicorp/memberlist) 检测到节点发生故障, 同时新的节点会从故障节点上接管这些 IP.

#### 局限性

L2模式有两个主要局限性: 单点的瓶颈、潜在的缓慢故障转移.

如上面说的, 在 L2 模式下, 一个被选举的单一的领袖节点会接收所有的 Service IPs 的流量. 这意味着, 你服务的入口带宽受限与这个单一节点的带宽. 如果使用 ARP/NDP 引导流量, 这是一个基本限制.

当前的实现, 节点之间的故障转移依赖客户端之间的配合. 当故障发生时, MetalLB 会不经请求的发送出一些2层的数据包, 来通知其他客户端 Service IP 所对应的 MAC 地址已经更改.

大多数操作系统能正确处理这种数据包, 同时更新“邻居”的缓存. 这种情况下, 故障转移也就几秒钟. 但是, 有一些系统要么没有实现这种报文的处理, 要么实现了, 但是更新缓存很慢.

所有现代版本的操作系统都正确实现了 L2 故障转移, 比如 Windows、Mac、Linux. 所以, 出问题的仅仅是很老或者不常见的操作系统.

为了最大限度地减少计划内的故障转移对有故障的客户端的影响，您应该让旧的领袖节点多运行几分从, 以便它可以继续为旧客户端转发流量，直到它们的缓存刷新。

当一个计划之外的故障出现时. 在访问出错的客户端刷新它们的缓存之前, Service IPs 将不可达.

#### 和 keepalive 比较

MetalLB 的2层模式和 keepalived 有很多相似之处. 所以, 如果你熟悉 keepalived, 我说的很多你应该很熟悉. 但是和它也有一些不同的地方需要说一下.

Keepalived 使用虚拟路由器冗余协议(VRRP). Keepalived 的各实例之间不断地相互交换 VRRP 消息，以选择领袖并监控该领导者何时离开。

但是, MetalLB 却是依赖 memberlist 项目来知道什么时候集群中的节点不可达, 什么时候这个节点的 Service IPs 需要移动到别处.

Keepalived 和 MetalLB 从客户端的角度“看起来”是一样的：当发生故障转移时，Service IP 地址从一台机器迁移到另一台机器，之后该机器就会有多个 IP 地址。

因为它不用 VRRP, MetalLB 并不会有这个协议本身的局限性. 比如: VRRP协议限制每个网络只能用255个负载负载均衡器, 但是 MetalLB 就没有这个限制. 你可以有很多负载均衡的 IPs, 只要你网络中有空闲 IPs. MetalLB 的配置比 Keepalived 少, 比如, 它不需要 `Virtual Router IDs`.

另一方面，由于 MetalLB 依赖于 memberlist 来获取集群成员信息，它无法与第三方 VRRP 感知路由器和基础设施进行互操作。 这是设计之初规定好的: MetalLB 专门设计**用于在 Kubernetes 集群内**提供负载平衡和故障转移.

### BGP模式

在 BGP 模式下，集群中的每个节点都会与您的网络路由器建立 BGP 对等会话，并使用该对等会话来通告外部集群服务的 IP.

假设您的路由器配置为支持多路径，这将实现真正的负载平衡: MetalLB 发布的路由彼此等效。这意味着路由器将使用所有下一跳，并在它们之间进行负载平衡.

数据包到达节点后，kube-proxy 负责流量路由的最后一跳，将数据包送到服务中的特定 pod.

#### 负载均衡行为

负载均衡的确切行为取决于您的特定路由器型号和配置，但常见的行为是基于 `packet-hash` 方法在连接层面 `per-connection` 进行平衡。这是什么意思?

这个`per-connection`意味着单个 TCP 或 UDP 会话的**所有数据包**将被定向到集群中的单个机器。流量传播只发生在不同的连接之间，而不是一个连接内的数据包. 这是一件好事，因为在多个集群节点上传播数据包会导致一些问题：  

- 跨多个传输路径传播单个连接会导致数据包(packet)在线路上重新排序，这会极大地影响终端主机的性能。
- 在 Kubernetes 中, 不能保证节点之间流量的路由保持一致。这意味着两个不同的节点可以将同一连接的数据包(packet)路由到不同的 Pod，这将导致连接失败。

高性能路由器能够以一种无状态的方式在多个后端之间使用数据包哈希的方法散布数据包. 对于每一个数据包, 它们拥有一些属性, 并能用它作为 “种子” 来决定选择哪一个后端. 如果, 所有的属性都一样, 它们就会选择同一个后端. 

具体使用哪种哈希方法取决于路由器的硬件和软件. 典型的方法是: `3-tuple` 和 `5-tuple`. 3-tuple 哈希法使用数据包中的协议、源IP、目的IP作为哈希键, 这意味着来自不同ip的数据包会进入同一个后端. 5-tuple 哈希法又在其中加入了源端口和目的端口, 所有来自相同客户端的不同连接将会在集群中散布. 

通常, 我们推荐加入尽可能多的属性来参与数据包哈希, 也就是说使用更多的属性是非常好的. 因为这样会更加接近理想的负载均衡状态, 每一个节点都会收到相同数量的数据包. 但是我们永远不会达到这种理想状态, 因为上述原因, 但是我们能做的就是尽可能的均匀的传播连接, 以防止出现主机热点.

> 一个连接(connection)由多个连续的数据包(packet)构成

#### 局限性

使用 BGP 作为负载均衡机制可以让你使用标准的路由器硬件, 而不是定制的负载均衡器. 但是, 这也带来的一些缺点:

最大的缺点是基于 BGP 的负载平衡不能优雅地响应后端设置的地址更改. 也就是说, 当集群的一个节点下线了, 到你服务的所有成功的连接都会损坏(用户会看到报错:`Connection reset by peer`)

基于 BGP 的路由器实现无状态负载均衡。 他们通过哈希数据包头中的一些字段并将该哈希用作可用后端数组的索引，将给定数据包分配给特定的下一跳。

问题是路由器中使用的哈希值通常*不稳定*，所以每当后端集的大小发生变化时（例如，当一个节点的 BGP 会话关闭时），现有的连接将被有效地随机重新哈希，这意味着大多数现有的 连接最终会突然被转发到不同的后端，一个不知道相关连接的后端。

结果是每当你的服务的 `IP > Node` 映射发生变化时, 你希望看到一次性干净的切换出现, 到该服务的大部分所有可用连接中断. 没有持续的丢包或者黑洞, 只是一次很干净的中断而已.

根据您的服务的用途，您可以采用几种缓解策略：

- 你的 BGP 路由器可能有更加稳定的ECMP哈希算法. 有时候可能叫: `弹性ECMP` 或 `弹性LAG`. 使用这样的算法, 在后端集合发生变化的时候, 能有效的减少受影响的连接数量.
- 把你的服务部署到特定的节点上, 来减小节点池的大小, 它需要你小心的照顾.
- 把服务的变更安排在流量的低谷时候, 此时你的用户在睡觉流量很低.
- 把每一个逻辑上的服务拆分成两个有着不同 IP 的 kubernetes 服务, 使用DNS服务优雅的将用户流量从将要中断的服务迁移到另一个服务上.
- 在客户端添加重试逻辑, 以优雅地从突然断开连接中恢复. 如果您的客户是移动应用程序或丰富的单页网络应用程序, 这尤其适用.
- 将您的服务放在 ingress 控制器后面. ingress 控制器本身可以使用 MetalLB 来接收流量, 但是在 BGP 和您的服务之间有一个状态层意味着您可以毫无顾虑地更改您的服务。 您只需在更改 ingress 控制器本身的部署时小心(例如, 在添加更多 NGINX pod 时).
- 接受偶尔会出现重置连接的情况. 对于低可用性的内部服务, 这可能是可以接受的.

#### FRR 模式

MetalLB 提供了一个实验模式: 使用 FRR 作为 BGP 层的后端.

开启 FRR 模式之后, 会获得以下额外的特性:

- BFD 支持的 BGP 会话
- BGP 和 BFD 支持 IPv6

#### FRR 模式的局限性

相比与原生实现, FRR 模式有以下局限性:

- BGPAdvertisement 的 RouterID 字段可以被覆盖，但它必须对所有的 advertisements 都相同（不能有不同的 advertisements 具有不同的 RouterID）。
- BGPAdvertisement 的 myAsn 字段可以被覆盖，但它必须对所有 advertisements 都相同(不能有不同的 advertisements 具有不同的 myAsn)
- 如果 eBGP Peer 是距离节点多跳的, 则 ebgp-multihop 标志必须设置为 true

## 安装

安装之前, 确保满足所有[要求](). 尤其是, 你要注意[网络附加组件的兼容性]()

## 配置

...

## 使用

...

```
Copyright © The MetalLB Contributors.
Copyright © 2021 The Linux Foundation ®. All rights reserved. Linux 基金会已注册商标并使用商标.
```